{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cf8381",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "Scikit learn provides a large variety of algorithms for some common Machine Learning tasks, such as:\n",
    "\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "* Feature Selection\n",
    "* Anomaly Detection\n",
    "\n",
    "It also provides some datasets that you can use to test these algorithms:\n",
    "\n",
    "* Classification Datasets:\n",
    "    * Breast cancer wisconsin\n",
    "    * Iris plants (3-classes)\n",
    "    * Optical recognition of handwritten digits (10-classes)\n",
    "    * Wine (n-classes)\n",
    "\n",
    "* Regression Datasets: \n",
    "    * Boston house prices \n",
    "    * Diabetes\n",
    "    * Linnerrud (multiple regression)\n",
    "    * California Housing\n",
    "\n",
    "* Image: \n",
    "    * The Olivetti faces\n",
    "    * The Labeled Faces in the Wild face recognition\n",
    "    * Forest covertypes\n",
    "\n",
    "* NLP:\n",
    "    * News group\n",
    "    * Reuters Corpus Volume I \n",
    "\n",
    "* Other:\n",
    "    * Kddcup 99- Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99393d-fedd-451f-a9f6-3f2c7a8b3aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7fbe7-013f-4422-a528-d0e2a438c1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4e3b6e9",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Use the full [Kddcup](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset to compare classification performance of 3 different classifiers. \n",
    "    * Separate the data into train, validation, and test. \n",
    "    * Use accuracy as the metric for assessing performance. \n",
    "    * For each classifier, identify the hyperparameters. Perform optimization over at least 2 hyperparameters.   \n",
    "    * Compare the performance of the optimal configuration of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18662c",
   "metadata": {},
   "source": [
    "## Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1c631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "D = fetch_kddcup99(as_frame=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d561eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration protocol_type  service   flag src_bytes dst_bytes land  \\\n",
       "0        0        b'tcp'  b'http'  b'SF'       181      5450    0   \n",
       "1        0        b'tcp'  b'http'  b'SF'       239       486    0   \n",
       "2        0        b'tcp'  b'http'  b'SF'       235      1337    0   \n",
       "3        0        b'tcp'  b'http'  b'SF'       219      1337    0   \n",
       "4        0        b'tcp'  b'http'  b'SF'       217      2032    0   \n",
       "\n",
       "  wrong_fragment urgent hot  ... dst_host_count dst_host_srv_count  \\\n",
       "0              0      0   0  ...              9                  9   \n",
       "1              0      0   0  ...             19                 19   \n",
       "2              0      0   0  ...             29                 29   \n",
       "3              0      0   0  ...             39                 39   \n",
       "4              0      0   0  ...             49                 49   \n",
       "\n",
       "  dst_host_same_srv_rate dst_host_diff_srv_rate dst_host_same_src_port_rate  \\\n",
       "0                    1.0                    0.0                        0.11   \n",
       "1                    1.0                    0.0                        0.05   \n",
       "2                    1.0                    0.0                        0.03   \n",
       "3                    1.0                    0.0                        0.03   \n",
       "4                    1.0                    0.0                        0.02   \n",
       "\n",
       "  dst_host_srv_diff_host_rate dst_host_serror_rate dst_host_srv_serror_rate  \\\n",
       "0                         0.0                  0.0                      0.0   \n",
       "1                         0.0                  0.0                      0.0   \n",
       "2                         0.0                  0.0                      0.0   \n",
       "3                         0.0                  0.0                      0.0   \n",
       "4                         0.0                  0.0                      0.0   \n",
       "\n",
       "  dst_host_rerror_rate dst_host_srv_rerror_rate  \n",
       "0                  0.0                      0.0  \n",
       "1                  0.0                      0.0  \n",
       "2                  0.0                      0.0  \n",
       "3                  0.0                      0.0  \n",
       "4                  0.0                      0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(D.data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b623a4-b1b2-4de2-a0ba-23c44358e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'tcp', b'udp', b'icmp'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,[1,2,3]] #non numerical columns-- model fit throwing error\n",
    "df['protocol_type'].unique()\n",
    "#df['service'].unique()\n",
    "#df['flag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc2091f-3bea-407e-b080-736153720149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>ptype_b'icmp'</th>\n",
       "      <th>ptype_b'tcp'</th>\n",
       "      <th>ptype_b'udp'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration  service   flag src_bytes dst_bytes land wrong_fragment urgent hot  \\\n",
       "0        0  b'http'  b'SF'       181      5450    0              0      0   0   \n",
       "1        0  b'http'  b'SF'       239       486    0              0      0   0   \n",
       "2        0  b'http'  b'SF'       235      1337    0              0      0   0   \n",
       "3        0  b'http'  b'SF'       219      1337    0              0      0   0   \n",
       "4        0  b'http'  b'SF'       217      2032    0              0      0   0   \n",
       "\n",
       "  num_failed_logins  ... dst_host_diff_srv_rate dst_host_same_src_port_rate  \\\n",
       "0                 0  ...                    0.0                        0.11   \n",
       "1                 0  ...                    0.0                        0.05   \n",
       "2                 0  ...                    0.0                        0.03   \n",
       "3                 0  ...                    0.0                        0.03   \n",
       "4                 0  ...                    0.0                        0.02   \n",
       "\n",
       "  dst_host_srv_diff_host_rate dst_host_serror_rate dst_host_srv_serror_rate  \\\n",
       "0                         0.0                  0.0                      0.0   \n",
       "1                         0.0                  0.0                      0.0   \n",
       "2                         0.0                  0.0                      0.0   \n",
       "3                         0.0                  0.0                      0.0   \n",
       "4                         0.0                  0.0                      0.0   \n",
       "\n",
       "  dst_host_rerror_rate dst_host_srv_rerror_rate ptype_b'icmp' ptype_b'tcp'  \\\n",
       "0                  0.0                      0.0             0            1   \n",
       "1                  0.0                      0.0             0            1   \n",
       "2                  0.0                      0.0             0            1   \n",
       "3                  0.0                      0.0             0            1   \n",
       "4                  0.0                      0.0             0            1   \n",
       "\n",
       "  ptype_b'udp'  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_enc = pd.get_dummies(df['protocol_type'], prefix='ptype', dtype = 'int')\n",
    "pt_enc.head()\n",
    "df = pd.concat([df, pt_enc], axis=1)\n",
    "df.drop('protocol_type', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4a712a-9a49-4738-8d5b-74a23f118b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>...</th>\n",
       "      <th>service_b'telnet'</th>\n",
       "      <th>service_b'tftp_u'</th>\n",
       "      <th>service_b'tim_i'</th>\n",
       "      <th>service_b'time'</th>\n",
       "      <th>service_b'urh_i'</th>\n",
       "      <th>service_b'urp_i'</th>\n",
       "      <th>service_b'uucp'</th>\n",
       "      <th>service_b'uucp_path'</th>\n",
       "      <th>service_b'vmnet'</th>\n",
       "      <th>service_b'whois'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration   flag src_bytes dst_bytes land wrong_fragment urgent hot  \\\n",
       "0        0  b'SF'       181      5450    0              0      0   0   \n",
       "1        0  b'SF'       239       486    0              0      0   0   \n",
       "2        0  b'SF'       235      1337    0              0      0   0   \n",
       "3        0  b'SF'       219      1337    0              0      0   0   \n",
       "4        0  b'SF'       217      2032    0              0      0   0   \n",
       "\n",
       "  num_failed_logins logged_in  ... service_b'telnet' service_b'tftp_u'  \\\n",
       "0                 0         1  ...                 0                 0   \n",
       "1                 0         1  ...                 0                 0   \n",
       "2                 0         1  ...                 0                 0   \n",
       "3                 0         1  ...                 0                 0   \n",
       "4                 0         1  ...                 0                 0   \n",
       "\n",
       "  service_b'tim_i' service_b'time' service_b'urh_i' service_b'urp_i'  \\\n",
       "0                0               0                0                0   \n",
       "1                0               0                0                0   \n",
       "2                0               0                0                0   \n",
       "3                0               0                0                0   \n",
       "4                0               0                0                0   \n",
       "\n",
       "  service_b'uucp' service_b'uucp_path' service_b'vmnet' service_b'whois'  \n",
       "0               0                    0                0                0  \n",
       "1               0                    0                0                0  \n",
       "2               0                    0                0                0  \n",
       "3               0                    0                0                0  \n",
       "4               0                    0                0                0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_enc = pd.get_dummies(df['service'], prefix='service', dtype = 'int')\n",
    "s_enc.head()\n",
    "df = pd.concat([df, s_enc], axis=1)\n",
    "df.drop('service', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be25e71-9add-4585-a63b-3b51c81a1468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_b'REJ'</th>\n",
       "      <th>flag_b'RSTO'</th>\n",
       "      <th>flag_b'RSTOS0'</th>\n",
       "      <th>flag_b'RSTR'</th>\n",
       "      <th>flag_b'S0'</th>\n",
       "      <th>flag_b'S1'</th>\n",
       "      <th>flag_b'S2'</th>\n",
       "      <th>flag_b'S3'</th>\n",
       "      <th>flag_b'SF'</th>\n",
       "      <th>flag_b'SH'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration src_bytes dst_bytes land wrong_fragment urgent hot  \\\n",
       "0        0       181      5450    0              0      0   0   \n",
       "1        0       239       486    0              0      0   0   \n",
       "2        0       235      1337    0              0      0   0   \n",
       "3        0       219      1337    0              0      0   0   \n",
       "4        0       217      2032    0              0      0   0   \n",
       "\n",
       "  num_failed_logins logged_in num_compromised  ... flag_b'REJ' flag_b'RSTO'  \\\n",
       "0                 0         1               0  ...           0            0   \n",
       "1                 0         1               0  ...           0            0   \n",
       "2                 0         1               0  ...           0            0   \n",
       "3                 0         1               0  ...           0            0   \n",
       "4                 0         1               0  ...           0            0   \n",
       "\n",
       "  flag_b'RSTOS0' flag_b'RSTR' flag_b'S0' flag_b'S1' flag_b'S2' flag_b'S3'  \\\n",
       "0              0            0          0          0          0          0   \n",
       "1              0            0          0          0          0          0   \n",
       "2              0            0          0          0          0          0   \n",
       "3              0            0          0          0          0          0   \n",
       "4              0            0          0          0          0          0   \n",
       "\n",
       "  flag_b'SF' flag_b'SH'  \n",
       "0          1          0  \n",
       "1          1          0  \n",
       "2          1          0  \n",
       "3          1          0  \n",
       "4          1          0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_enc = pd.get_dummies(df['flag'], prefix='flag', dtype = 'int')\n",
    "f_enc.head()\n",
    "df = pd.concat([df, f_enc], axis=1)\n",
    "df.drop('flag', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4e1c4-0fd9-4a41-a013-d0aca021318f",
   "metadata": {},
   "source": [
    "fixed that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cb6f4-b854-4b3d-bf26-6966778e9812",
   "metadata": {},
   "source": [
    "## Exercise 1: \n",
    "- Use the full Kddcup dataset to compare classification performance of 3 different classifiers.\n",
    "- Separate the data into train, validation, and test.\n",
    "- Use accuracy as the metric for assessing performance.\n",
    "- For each classifier, identify the hyperparameters. Perform optimization over at least 2 hyperparameters.\n",
    "- Compare the performance of the optimal configuration of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4b12e-303c-464d-a9d1-970cfaefd0ea",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09a210f-facc-43d3-8748-8bf3592778de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll try decision tree, knn, and neural net\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad519a9-e0db-45e8-9d31-2b61615c01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = D.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b1b6d4-4088-401b-bde3-9fc2c34b77f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  1,  7, 12,  9, 18,  3, 14, 20, 15,  5,  6,  2,  0,  4, 17, 13,\n",
       "       10,  8, 22, 21, 19, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "df['target']= target_label_encoder.fit_transform(df['target']) \n",
    "  \n",
    "df['target'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8904a0ff-9915-4806-a2e8-1a9ac239052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration          float32\n",
       "src_bytes         float32\n",
       "dst_bytes         float32\n",
       "land              float32\n",
       "wrong_fragment    float32\n",
       "                   ...   \n",
       "flag_b'S2'        float32\n",
       "flag_b'S3'        float32\n",
       "flag_b'SF'        float32\n",
       "flag_b'SH'        float32\n",
       "target            float32\n",
       "Length: 119, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype('float32')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1501f41-c876-4758-b8b2-bd0056cd4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca84d9cd-d248-4e11-bc3f-d0a74d70ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e01d0e-2cc1-496f-a635-2ad141dd2426",
   "metadata": {},
   "source": [
    "### KNN Tuning and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "196bde90-91e8-4458-b2c4-94f0b10f7d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END .......leaf_size=20, n_neighbors=3, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=20, n_neighbors=3, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=20, n_neighbors=7, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=20, n_neighbors=7, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=30, n_neighbors=3, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=30, n_neighbors=3, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=30, n_neighbors=7, weights=uniform; total time= 1.1min\n",
      "[CV] END .......leaf_size=30, n_neighbors=7, weights=uniform; total time= 1.1min\n",
      "Best Parameters: {'leaf_size': 20, 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best Score: 0.9982364074328975\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 7],\n",
    "    'weights': ['uniform'],\n",
    "    'leaf_size': [20, 30]\n",
    "}\n",
    "\n",
    "#getting error that classes are less than n_splits, so cv has to be 2, dont want to eliminate the smaller class yet\n",
    "g_search = GridSearchCV(neigh, param_grid, cv=2, scoring='accuracy', n_jobs = 1, verbose = 2)\n",
    "g_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", g_search.best_params_)\n",
    "print(\"Best Score:\", g_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb049715-ebd6-4631-aeaa-5f8148909237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best knn: KNeighborsClassifier(leaf_size=20, n_neighbors=3)\n",
      "best knn prediction: [18. 18. 18. ... 11. 18. 11.]\n"
     ]
    }
   ],
   "source": [
    "#best_knn = random_search.best_estimator_\n",
    "#y_pred = best_knn.predict(X_test)\n",
    "\n",
    "print('Best knn:', best_knn)\n",
    "print('best knn prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea771c-cc0e-422b-bf64-38a45b45f326",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0abd72-0ea6-4456-a849-bdafbd3ad482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] END ....svm__C=0.1, svm__gamma=0.05, svm__kernel=linear; total time=  19.2s\n",
      "[CV] END ....svm__C=0.1, svm__gamma=0.05, svm__kernel=linear; total time=  16.2s\n",
      "[CV] END .......svm__C=0.1, svm__gamma=5, svm__kernel=linear; total time=  18.9s\n",
      "[CV] END .......svm__C=0.1, svm__gamma=5, svm__kernel=linear; total time=  16.2s\n",
      "[CV] END ......svm__C=0.1, svm__gamma=25, svm__kernel=linear; total time=  18.7s\n",
      "[CV] END ......svm__C=0.1, svm__gamma=25, svm__kernel=linear; total time=  15.9s\n",
      "[CV] END ......svm__C=5, svm__gamma=0.05, svm__kernel=linear; total time=  15.7s\n",
      "[CV] END ......svm__C=5, svm__gamma=0.05, svm__kernel=linear; total time=  14.8s\n",
      "[CV] END .........svm__C=5, svm__gamma=5, svm__kernel=linear; total time=  15.9s\n",
      "[CV] END .........svm__C=5, svm__gamma=5, svm__kernel=linear; total time=  14.9s\n",
      "[CV] END ........svm__C=5, svm__gamma=25, svm__kernel=linear; total time=  15.8s\n",
      "[CV] END ........svm__C=5, svm__gamma=25, svm__kernel=linear; total time=  15.0s\n",
      "Best Parameters: {'svm__C': 5, 'svm__gamma': 0.05, 'svm__kernel': 'linear'}\n",
      "Best Score: 0.9993876766122829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#svm works best scaled\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),('svm', SVC())])\n",
    "\n",
    "param_grid = {'svm__C': [0.1, 5], 'svm__kernel': ['linear'], 'svm__gamma' : [.05, 5, 25]} #rbf and poly were taking days\n",
    "\n",
    "#getting error that classes are less than n_splits, so cv has to be 2, dont want to eliminate the smaller class yet\n",
    "\n",
    "g_search = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy', n_jobs = 1, verbose =2)\n",
    "g_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", g_search.best_params_)\n",
    "print(\"Best Score:\", g_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8f54ea-9eac-486f-8305-14f776823bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best svm: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svm', SVC(C=5, gamma=0.05, kernel='linear'))])\n",
      "best svm prediction: [18. 18. 18. ... 11. 18. 11.]\n"
     ]
    }
   ],
   "source": [
    "best_svm = g_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "print('Best svm:', best_svm)\n",
    "print('best svm prediction:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ec9a9-c04f-482b-a732-c2ebd83d15c8",
   "metadata": {},
   "source": [
    "### Neural Net (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea810dd2-6ec5-4b23-97fd-3a81eb9a6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47bb81b5-9172-4ddd-a414-5845cb656b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=  19.9s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50, 50), learning_rate=constant; total time=  35.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant; total time=  13.4s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant; total time=  40.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant; total time=  15.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant; total time= 1.5min\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=  40.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant; total time=  38.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time=  19.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive; total time= 1.6min\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=  20.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive; total time= 2.1min\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive; total time=  26.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive; total time= 2.2min\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50, 50), learning_rate=adaptive; total time=  51.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50, 50), learning_rate=adaptive; total time= 1.8min\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant; total time=  59.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant; total time= 3.3min\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50, 50), learning_rate=adaptive; total time=  28.2s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(50, 50), learning_rate=adaptive; total time= 2.0min\n",
      "Best Parameters: {'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "Best Score: 0.9975178130440063\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(mlp, param_grid, cv=2, scoring='accuracy', n_jobs = 1, verbose =2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daea003-fdff-4e59-aca7-d79a2de812e8",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04066f15-5fe4-42ec-a3c7-4e4c9d06be4e",
   "metadata": {},
   "source": [
    "The model with the best performance was the \n",
    "Create an ensemble of at least 25 models, and use them for the classification task. Identify the top and bottom 10% of the data in terms of uncertainty of the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc2bf83-4d89-40ed-b67a-400afb2ab70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n",
      "model added\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def ensemble(n_models):\n",
    "    ensemble_preds = []\n",
    "    for i in range(n_models):\n",
    "        #boostrap training data with random state\n",
    "        X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train, replace=True, n_samples=len(X_train), random_state=i)\n",
    "        #use best model to fit\n",
    "        best_svm.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "        pred = best_svm.predict(X_test)\n",
    "        ensemble_preds.append(pred)\n",
    "        print('model added')\n",
    "    return ensemble_preds\n",
    "\n",
    "ensemble_predictions = ensemble(25)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc35a589-94c4-4e21-aa17-5705df06dbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea6416e-652b-474a-8f1f-ba59236b1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ensemble_preds = np.array(ensemble_predictions)\n",
    "prediction_variances = np.std(ensemble_preds, axis=0)\n",
    "\n",
    "\n",
    "top_10_percent_uncertainty = np.argsort(prediction_variances)[-int(0.1 * len(prediction_variances)):]\n",
    "bottom_10_percent_uncertainty = np.argsort(prediction_variances)[:int(0.1 * len(prediction_variances))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "454b029a-9242-4c60-9362-b32f18dc7c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top_10_percent_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ed87a-d777-46e8-aa8a-5994ff1d5367",
   "metadata": {},
   "source": [
    "## 3. Use 2 different feature selection algorithm to identify the 10 most important features for the task in question 1. Retrain classifiers in question 1 with just this subset of features and compare performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2062b0d-afe4-4635-b067-1a391d360699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]  # Sort in descending order\n",
    "\n",
    "\n",
    "top_10_rf = indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad51c800-0a2e-413a-b4b9-25a2ef0b8c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19,   1,  38,  55,  20,  26,  32, 116,  29,  30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d8774-9fe2-4104-afcb-93605774115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "bestparam = SVC(C=5, gamma=0.05, kernel='linear')\n",
    "selector = RFE(estimator=bestparam, n_features_to_select=10, step=1)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "top_10_rfe = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d532dd-6fc2-4a73-a085-4fa99737dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "873aff4f-fe76-421e-b4e5-9a33f146058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Subset the data to include only the top 10 features from Random Forest\n",
    "X_train_rf_top_10 = X_train.iloc[:, top_10_rf]\n",
    "X_test_rf_top_10 = X_test.iloc[:, top_10_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f43f392b-3d9a-4063-91c0-1604451e1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score: 0.9803856080157887\n"
     ]
    }
   ],
   "source": [
    "# Retrain\n",
    "svm_top_10 = LinearSVC(C=5, max_iter=10000, tol=1e-3)\n",
    "svm_top_10.fit(X_train_rf_top_10, y_train)\n",
    "y_pred = svm_top_10.predict(X_test_rf_top_10)\n",
    "print(\"SVM Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2846be1-67db-4be9-b031-fc336e42fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score: 0.9974697636759273\n"
     ]
    }
   ],
   "source": [
    "knn_t10 = KNeighborsClassifier(leaf_size=20, n_neighbors=3)\n",
    "knn_t10.fit(X_train_rf_top_10, y_train)\n",
    "y_pred = knn_t10.predict(X_test_rf_top_10)\n",
    "print(\"KNN Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dff23eaf-5d81-48b3-8bf6-e6efab263b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score: 0.9849197915085269\n"
     ]
    }
   ],
   "source": [
    "mlp_t10 = MLPClassifier(learning_rate= 'constant', hidden_layer_sizes=(100,), alpha= 0.0001)\n",
    "mlp_t10.fit(X_train_rf_top_10, y_train)\n",
    "y_pred = mlp_t10.predict(X_test_rf_top_10)\n",
    "print(\"MLP Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7a81c-e0da-437a-aec4-a0efcbb8fe1f",
   "metadata": {},
   "source": [
    "### With the selected features from the random forest algorithm, the KNN, SVM, and MLP had reduced performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bcb77-f674-477b-9eb4-6315895cd1b3",
   "metadata": {},
   "source": [
    "## 4. Use the same data, removing the labels, and compare performance of 3 different clustering algorithms. Can you find clusters for each of the classes in question 1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c64f2e-dc72-40a2-9b5c-9147cf688e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=15, random_state=42, batch_size=500, n_init=3, max_iter=50)\n",
    "minibatch_kmeans_labels = minibatch_kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e61ce6e-0c83-4350-8db7-9369e7c6028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  9  9 ...  9  9  9]\n"
     ]
    }
   ],
   "source": [
    "centroids = minibatch_kmeans.cluster_centers_\n",
    "print(minibatch_kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "483fd192-2037-4dd1-abb2-cfd1c2df2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 114, 1: 17854, 2: 234587, 3: 34941, 4: 59646, 5: 3598, 6: 4390, 7: 3531, 8: 190, 9: 26791, 10: 945, 11: 9319, 12: 18417, 13: 27632, 14: 52066}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(minibatch_kmeans.labels_, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fabebc6-aa17-468a-84f1-e31d5ccb8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=10000, random_state=42)\n",
    "Xs_t10 = X_sample.iloc[:, top_10_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7031fb33-f1e2-46d1-b86c-b63a586c3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels = dbscan.fit_predict(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0edb2002-c3d3-4633-a145-4237cc214e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster (including noise):\n",
      "{-1: 4289, 0: 3918, 1: 7, 2: 658, 3: 5, 4: 30, 5: 7, 6: 13, 7: 8, 8: 521, 9: 13, 10: 9, 11: 105, 12: 16, 13: 5, 14: 7, 15: 17, 16: 10, 17: 15, 18: 5, 19: 9, 20: 5, 21: 8, 22: 9, 23: 10, 24: 16, 25: 10, 26: 5, 27: 7, 28: 18, 29: 7, 30: 20, 31: 5, 32: 6, 33: 6, 34: 7, 35: 6, 36: 11, 37: 14, 38: 10, 39: 6, 40: 5, 41: 5, 42: 9, 43: 6, 44: 5, 45: 15, 46: 14, 47: 10, 48: 12, 49: 5, 50: 9, 51: 6, 52: 13, 53: 6, 54: 6, 55: 9, 56: 6, 57: 6}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster (including noise):\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "555e4a38-d3d4-406b-b4a2-44d031291461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=None, distance_threshold = 10000, linkage=\"ward\")\n",
    "\n",
    "# Fit the model and predict clusters\n",
    "labels = hierarchical_clustering.fit_predict(X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4564a28-9d94-4b9c-9c74-1b3ee4e76259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 2705, 1: 27, 2: 40, 3: 8, 4: 16, 5: 280, 6: 92, 7: 14, 8: 12, 9: 57, 10: 95, 11: 2, 12: 59, 13: 2, 14: 7, 15: 59, 16: 24, 17: 53, 18: 133, 19: 138, 20: 7, 21: 1, 22: 401, 23: 1, 24: 46, 25: 1, 26: 3, 27: 1, 28: 1060, 29: 1, 30: 2, 31: 1, 32: 4612, 33: 1, 34: 8, 35: 1, 36: 5, 37: 2, 38: 9, 39: 1, 40: 13}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7b9cad9-461f-4d6f-8a8d-7b33c98cbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "mean_shift = MeanShift()\n",
    "labels = mean_shift.fit_predict(X_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee59e079-32eb-47e8-a74d-1fe3cde68aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 9785, 1: 46, 2: 17, 3: 89, 4: 8, 5: 8, 6: 8, 7: 11, 8: 5, 9: 6, 10: 2, 11: 2, 12: 2, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c471851-4211-47b7-a380-880fbb424d91",
   "metadata": {},
   "source": [
    "## 5. Can you identify any clusters within the top/bottom 10% identified in 2. What are their characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1b7e0-0276-4128-aeee-b9411cfbbd38",
   "metadata": {},
   "source": [
    "### Trying reduced dimensionality with chosen features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a63cdf4f-cf8c-4b23-af39-b6083d8f8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=15)\n",
    "labels = dbscan.fit_predict(Xs_t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea938a9e-8d85-4358-a412-1550e487126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster (including noise, -1):\n",
      "{-1: 4544, 0: 3918, 1: 658, 2: 34, 3: 30, 4: 521, 5: 25, 6: 105, 7: 16, 8: 29, 9: 17, 10: 18, 11: 16, 12: 16, 13: 18, 14: 20, 15: 15}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster (including noise, -1):\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a341e406-5d0e-4a18-bb54-da4e35fb58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#hierarchical_clustering = AgglomerativeClustering(n_clusters=None, distance_threshold = 10000, linkage=\"ward\")\n",
    "# Fit the model and predict clusters\n",
    "#labels = hierarchical_clustering.fit_predict(Xs_t10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a190881f-f4eb-4463-ae7c-b9231fc9e498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 2, 1: 16, 2: 1683, 3: 214, 4: 2314, 5: 2, 6: 10, 7: 26, 8: 1060, 9: 2, 10: 1, 11: 46, 12: 4616, 13: 1, 14: 6, 15: 1}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5504f3-e68d-4e79-83c5-501ebec4111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "mean_shift = MeanShift()\n",
    "labels = mean_shift.fit_predict(Xs_t10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "653e09cd-b753-483d-8962-240c077dd77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 9898, 1: 46, 2: 11, 3: 20, 4: 9, 5: 6, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5c133-4edb-46b9-9d36-09f67f8faf23",
   "metadata": {},
   "source": [
    "### Trying with top and bottom 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b082a938-e939-4dde-ba8b-f7a74f649107",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(X_test)  # Start with the test set data\n",
    "\n",
    "top_10_percent_uncertainty = top_10_percent_uncertainty.astype(int)\n",
    "bottom_10_percent_uncertainty = bottom_10_percent_uncertainty.astype(int)\n",
    "\n",
    "# Add predictions and uncertainty as columns\n",
    "result_df['ensemble_predictions'] = ensemble_preds.mean(axis=0)  # Average predictions across all models\n",
    "result_df['prediction_variance'] = prediction_variances  # Add the uncertainty values\n",
    "    \n",
    "# Add the top and bottom uncertainty results\n",
    "result_df['uncertainty'] = 'None'  # Default label\n",
    "uncertainty_column_pos = result_df.columns.get_loc('uncertainty')\n",
    "\n",
    "\n",
    "# Label the rows with top 10% uncertainty\n",
    "result_df.iloc[top_10_percent_uncertainty, uncertainty_column_pos] = 'Top 10% uncertainty'\n",
    "result_df.iloc[bottom_10_percent_uncertainty, uncertainty_column_pos] = 'Bottom 10% uncertainty'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca76d55-32e5-40fc-bf83-9fd48d274a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()\n",
    "subset_df = result_df[result_df['uncertainty'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b067f00-99b1-4051-b02d-60832c6a578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_b'RSTR'</th>\n",
       "      <th>flag_b'S0'</th>\n",
       "      <th>flag_b'S1'</th>\n",
       "      <th>flag_b'S2'</th>\n",
       "      <th>flag_b'S3'</th>\n",
       "      <th>flag_b'SF'</th>\n",
       "      <th>flag_b'SH'</th>\n",
       "      <th>ensemble_predictions</th>\n",
       "      <th>prediction_variance</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343725</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.60</td>\n",
       "      <td>1.959592</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.388877</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>3.413854</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "317921       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "343725     189.0        0.0        0.0   0.0             0.0     0.0  0.0   \n",
       "53252        0.0      215.0        0.0   0.0             0.0     0.0  0.0   \n",
       "91622        0.0        6.0      144.0   0.0             0.0     0.0  1.0   \n",
       "140587       0.0        1.0        0.0   0.0             0.0     0.0  0.0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  flag_b'RSTR'  \\\n",
       "317921                0.0        0.0              0.0  ...           0.0   \n",
       "343725                0.0        0.0              0.0  ...           1.0   \n",
       "53252                 0.0        0.0              0.0  ...           0.0   \n",
       "91622                 0.0        1.0              0.0  ...           0.0   \n",
       "140587                0.0        0.0              0.0  ...           0.0   \n",
       "\n",
       "        flag_b'S0'  flag_b'S1'  flag_b'S2'  flag_b'S3'  flag_b'SF'  \\\n",
       "317921         0.0         0.0         0.0         0.0         1.0   \n",
       "343725         0.0         0.0         0.0         0.0         0.0   \n",
       "53252          0.0         0.0         0.0         0.0         1.0   \n",
       "91622          0.0         0.0         1.0         0.0         0.0   \n",
       "140587         0.0         0.0         0.0         0.0         1.0   \n",
       "\n",
       "        flag_b'SH'  ensemble_predictions  prediction_variance  \\\n",
       "317921         0.0                 18.00             0.000000   \n",
       "343725         0.0                 12.60             1.959592   \n",
       "53252          0.0                 10.60             1.897367   \n",
       "91622          0.0                  6.60             5.388877   \n",
       "140587         0.0                 13.16             3.413854   \n",
       "\n",
       "                   uncertainty  \n",
       "317921  Bottom 10% uncertainty  \n",
       "343725     Top 10% uncertainty  \n",
       "53252      Top 10% uncertainty  \n",
       "91622      Top 10% uncertainty  \n",
       "140587     Top 10% uncertainty  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4ed94b9-20d1-4e98-abd1-25e3bfef21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_b'REJ'</th>\n",
       "      <th>flag_b'RSTO'</th>\n",
       "      <th>flag_b'RSTOS0'</th>\n",
       "      <th>flag_b'RSTR'</th>\n",
       "      <th>flag_b'S0'</th>\n",
       "      <th>flag_b'S1'</th>\n",
       "      <th>flag_b'S2'</th>\n",
       "      <th>flag_b'S3'</th>\n",
       "      <th>flag_b'SF'</th>\n",
       "      <th>flag_b'SH'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343725</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485178</th>\n",
       "      <td>45.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>4201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41718</th>\n",
       "      <td>15127.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>185137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18458</th>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19760 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "317921       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "343725     189.0        0.0        0.0   0.0             0.0     0.0  0.0   \n",
       "53252        0.0      215.0        0.0   0.0             0.0     0.0  0.0   \n",
       "91622        0.0        6.0      144.0   0.0             0.0     0.0  1.0   \n",
       "140587       0.0        1.0        0.0   0.0             0.0     0.0  0.0   \n",
       "...          ...        ...        ...   ...             ...     ...  ...   \n",
       "485178      45.0     2336.0     4201.0   0.0             0.0     0.0  3.0   \n",
       "759          0.0        8.0        0.0   0.0             0.0     0.0  0.0   \n",
       "41718    15127.0     1229.0   185137.0   0.0             0.0     0.0  0.0   \n",
       "39370        0.0        0.0        0.0   0.0             0.0     0.0  0.0   \n",
       "18458        0.0      316.0      343.0   0.0             0.0     0.0  0.0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  flag_b'REJ'  \\\n",
       "317921                0.0        0.0              0.0  ...          0.0   \n",
       "343725                0.0        0.0              0.0  ...          0.0   \n",
       "53252                 0.0        0.0              0.0  ...          0.0   \n",
       "91622                 0.0        1.0              0.0  ...          0.0   \n",
       "140587                0.0        0.0              0.0  ...          0.0   \n",
       "...                   ...        ...              ...  ...          ...   \n",
       "485178                0.0        1.0              1.0  ...          0.0   \n",
       "759                   0.0        0.0              0.0  ...          0.0   \n",
       "41718                 0.0        1.0            767.0  ...          0.0   \n",
       "39370                 0.0        0.0              0.0  ...          1.0   \n",
       "18458                 0.0        1.0              0.0  ...          0.0   \n",
       "\n",
       "        flag_b'RSTO'  flag_b'RSTOS0'  flag_b'RSTR'  flag_b'S0'  flag_b'S1'  \\\n",
       "317921           0.0             0.0           0.0         0.0         0.0   \n",
       "343725           0.0             0.0           1.0         0.0         0.0   \n",
       "53252            0.0             0.0           0.0         0.0         0.0   \n",
       "91622            0.0             0.0           0.0         0.0         0.0   \n",
       "140587           0.0             0.0           0.0         0.0         0.0   \n",
       "...              ...             ...           ...         ...         ...   \n",
       "485178           0.0             0.0           0.0         0.0         0.0   \n",
       "759              0.0             0.0           0.0         0.0         0.0   \n",
       "41718            0.0             0.0           0.0         0.0         0.0   \n",
       "39370            0.0             0.0           0.0         0.0         0.0   \n",
       "18458            0.0             0.0           0.0         0.0         0.0   \n",
       "\n",
       "        flag_b'S2'  flag_b'S3'  flag_b'SF'  flag_b'SH'  \n",
       "317921         0.0         0.0         1.0         0.0  \n",
       "343725         0.0         0.0         0.0         0.0  \n",
       "53252          0.0         0.0         1.0         0.0  \n",
       "91622          1.0         0.0         0.0         0.0  \n",
       "140587         0.0         0.0         1.0         0.0  \n",
       "...            ...         ...         ...         ...  \n",
       "485178         0.0         0.0         1.0         0.0  \n",
       "759            0.0         0.0         1.0         0.0  \n",
       "41718          0.0         0.0         1.0         0.0  \n",
       "39370          0.0         0.0         0.0         0.0  \n",
       "18458          0.0         0.0         1.0         0.0  \n",
       "\n",
       "[19760 rows x 118 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e633810-3f67-42b7-b14d-52e7025dd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=15)\n",
    "labels = dbscan.fit_predict(subset_df.iloc[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e94964c8-18d6-4e6b-8f7f-e3e434b885ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster (including noise, -1):\n",
      "{-1: 8673, 0: 7704, 1: 27, 2: 27, 3: 1377, 4: 197, 5: 1046, 6: 19, 7: 22, 8: 37, 9: 24, 10: 22, 11: 17, 12: 21, 13: 20, 14: 17, 15: 55, 16: 32, 17: 21, 18: 17, 19: 26, 20: 15, 21: 31, 22: 22, 23: 15, 24: 28, 25: 15, 26: 27, 27: 36, 28: 28, 29: 29, 30: 23, 31: 22, 32: 22, 33: 16, 34: 15, 35: 15}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster (including noise, -1):\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cb10933-4413-41e0-bb82-b707733004b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=None, distance_threshold = 10000, linkage=\"ward\")\n",
    "# Fit the model and predict clusters\n",
    "labels = hierarchical_clustering.fit_predict(subset_df.iloc[:,:-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f43aaf7-c1cf-40fa-b4c9-0c6c64e9536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 33, 1: 4, 2: 14, 3: 1434, 4: 4, 5: 2, 6: 95, 7: 293, 8: 30, 9: 169, 10: 4, 11: 2, 12: 13, 13: 519, 14: 10, 15: 19, 16: 57, 17: 158, 18: 30, 19: 1, 20: 1, 21: 4431, 22: 9, 23: 288, 24: 81, 25: 90, 26: 22, 27: 77, 28: 16, 29: 39, 30: 2194, 31: 5, 32: 1, 33: 9093, 34: 35, 35: 1, 36: 1, 37: 72, 38: 33, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 77, 46: 11, 47: 1, 48: 1, 49: 2, 50: 1, 51: 1, 52: 13, 53: 1, 54: 258, 55: 1, 56: 6, 57: 1}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae8074-54fe-4480-9647-795e79aa99e4",
   "metadata": {},
   "source": [
    "### with top 10 features of the uncertain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a0b659-348e-4533-a1d6-314a07cbf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset_df.iloc[:,:-3]\n",
    "Xst10_u = subset.iloc[:, top_10_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "704a0930-bb70-4634-9510-50a1a6d1e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster (including noise, -1):\n",
      "{-1: 8673, 0: 7704, 1: 27, 2: 27, 3: 1377, 4: 197, 5: 1046, 6: 19, 7: 22, 8: 37, 9: 24, 10: 22, 11: 17, 12: 21, 13: 20, 14: 17, 15: 55, 16: 32, 17: 21, 18: 17, 19: 26, 20: 15, 21: 31, 22: 22, 23: 15, 24: 28, 25: 15, 26: 27, 27: 36, 28: 28, 29: 29, 30: 23, 31: 22, 32: 22, 33: 16, 34: 15, 35: 15}\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=15)\n",
    "labels = dbscan.fit_predict(subset_df.iloc[:,:-3])\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster (including noise, -1):\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c32086ac-bf24-441d-b6b1-f0f8ab3a5f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each cluster:\n",
      "{0: 33, 1: 4, 2: 14, 3: 1434, 4: 4, 5: 2, 6: 95, 7: 293, 8: 30, 9: 169, 10: 4, 11: 2, 12: 13, 13: 519, 14: 10, 15: 19, 16: 57, 17: 158, 18: 30, 19: 1, 20: 1, 21: 4431, 22: 9, 23: 288, 24: 81, 25: 90, 26: 22, 27: 77, 28: 16, 29: 39, 30: 2194, 31: 5, 32: 1, 33: 9093, 34: 35, 35: 1, 36: 1, 37: 72, 38: 33, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 77, 46: 11, 47: 1, 48: 1, 49: 2, 50: 1, 51: 1, 52: 13, 53: 1, 54: 258, 55: 1, 56: 6, 57: 1}\n"
     ]
    }
   ],
   "source": [
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=None, distance_threshold = 10000, linkage=\"ward\")\n",
    "# Fit the model and predict clusters\n",
    "labels = hierarchical_clustering.fit_predict(subset_df.iloc[:,:-3])\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "cluster_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Number of points in each cluster:\")\n",
    "print(cluster_counts)\n",
    "subset_df = subset_df.copy()\n",
    "subset_df['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29353758-9e4d-49bd-8637-9844e69fd1c0",
   "metadata": {},
   "source": [
    "Big clusters in agglomerative:\n",
    "3, 7, 13, 21, 23, 30, 33, 54\n",
    "smaller:\n",
    "9, 17, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d998058-183b-4dcb-b99c-5bd4a91db924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_b'S0'</th>\n",
       "      <th>flag_b'S1'</th>\n",
       "      <th>flag_b'S2'</th>\n",
       "      <th>flag_b'S3'</th>\n",
       "      <th>flag_b'SF'</th>\n",
       "      <th>flag_b'SH'</th>\n",
       "      <th>ensemble_predictions</th>\n",
       "      <th>prediction_variance</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323343</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312866</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303903</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279912</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bottom 10% uncertainty</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "317921       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "323343       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "312866       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "342570       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "275412       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "...          ...        ...        ...   ...             ...     ...  ...   \n",
       "303903       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "209408       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "254759       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "185672       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "279912       0.0     1032.0        0.0   0.0             0.0     0.0  0.0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  flag_b'S0'  \\\n",
       "317921                0.0        0.0              0.0  ...         0.0   \n",
       "323343                0.0        0.0              0.0  ...         0.0   \n",
       "312866                0.0        0.0              0.0  ...         0.0   \n",
       "342570                0.0        0.0              0.0  ...         0.0   \n",
       "275412                0.0        0.0              0.0  ...         0.0   \n",
       "...                   ...        ...              ...  ...         ...   \n",
       "303903                0.0        0.0              0.0  ...         0.0   \n",
       "209408                0.0        0.0              0.0  ...         0.0   \n",
       "254759                0.0        0.0              0.0  ...         0.0   \n",
       "185672                0.0        0.0              0.0  ...         0.0   \n",
       "279912                0.0        0.0              0.0  ...         0.0   \n",
       "\n",
       "        flag_b'S1'  flag_b'S2'  flag_b'S3'  flag_b'SF'  flag_b'SH'  \\\n",
       "317921         0.0         0.0         0.0         1.0         0.0   \n",
       "323343         0.0         0.0         0.0         1.0         0.0   \n",
       "312866         0.0         0.0         0.0         1.0         0.0   \n",
       "342570         0.0         0.0         0.0         1.0         0.0   \n",
       "275412         0.0         0.0         0.0         1.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "303903         0.0         0.0         0.0         1.0         0.0   \n",
       "209408         0.0         0.0         0.0         1.0         0.0   \n",
       "254759         0.0         0.0         0.0         1.0         0.0   \n",
       "185672         0.0         0.0         0.0         1.0         0.0   \n",
       "279912         0.0         0.0         0.0         1.0         0.0   \n",
       "\n",
       "        ensemble_predictions  prediction_variance             uncertainty  \\\n",
       "317921                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "323343                  18.0                  0.0     Top 10% uncertainty   \n",
       "312866                  18.0                  0.0     Top 10% uncertainty   \n",
       "342570                  18.0                  0.0     Top 10% uncertainty   \n",
       "275412                  18.0                  0.0     Top 10% uncertainty   \n",
       "...                      ...                  ...                     ...   \n",
       "303903                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "209408                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "254759                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "185672                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "279912                  18.0                  0.0  Bottom 10% uncertainty   \n",
       "\n",
       "        cluster  \n",
       "317921       33  \n",
       "323343       33  \n",
       "312866       33  \n",
       "342570       33  \n",
       "275412       33  \n",
       "...         ...  \n",
       "303903       33  \n",
       "209408       33  \n",
       "254759       33  \n",
       "185672       33  \n",
       "279912       33  \n",
       "\n",
       "[9093 rows x 122 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_3 = subset_df.loc[subset_df['cluster'] == 3]\n",
    "c_21 = subset_df.loc[subset_df['cluster'] == 21]\n",
    "c_30 = subset_df.loc[subset_df['cluster'] == 30]\n",
    "c_33 = subset_df.loc[subset_df['cluster'] == 33]\n",
    "c_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca6d7c22-7c95-4cb1-87e9-9c47b7b184f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18.0\n",
       "Name: ensemble_predictions, dtype: float32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_30['src_bytes'].unique()\n",
    "c_30['src_bytes'].mode()\n",
    "c_30[\"flag_b'SF'\"].mode()\n",
    "c_30['ensemble_predictions'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6ad0a81-ef57-4536-87b4-4013f070917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_33['src_bytes'].unique()\n",
    "c_33['src_bytes'].mode()\n",
    "c_33['uncertainty'].mode()\n",
    "c_33['ensemble_predictions'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc024b-2ee0-4a45-ae97-b86b5037bd52",
   "metadata": {},
   "source": [
    "### The cluster characteristics are not very homogenous, but the ones that are (33, 30) have the same or similar src_bytes values with a 1 for flag_b'SF', and 0.0 for all other values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e06c2-e552-47b7-ac11-11bf315afd94",
   "metadata": {},
   "source": [
    "# 6. Use the \"SA\" dataset to compare the performance of 3 different anomaly detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753218d1-eb65-4d24-9cd9-2eedd35fe60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "\n",
    "\n",
    "# Load and preprocess the SA dataset\n",
    "data = fetch_kddcup99(subset = 'SA', as_frame = True)\n",
    "X = pd.DataFrame(data.data)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6f15a6-76f0-494e-87e7-6212060b0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_enc = pd.get_dummies(X['protocol_type'], prefix='ptype', dtype = 'int')\n",
    "pt_enc.head()\n",
    "X = pd.concat([X, pt_enc], axis=1)\n",
    "X.drop('protocol_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f90b21-2901-40cf-96f2-258611ea7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_enc = pd.get_dummies(X['service'], prefix='service', dtype = 'int')\n",
    "s_enc.head()\n",
    "X = pd.concat([X, s_enc], axis=1)\n",
    "X.drop('service', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2219dd93-a277-4972-96d1-51ea87d04a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_enc = pd.get_dummies(X['flag'], prefix='flag', dtype = 'int')\n",
    "f_enc.head()\n",
    "X = pd.concat([X, f_enc], axis=1)\n",
    "X.drop('flag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d9dc43-c3c1-42af-8860-52aad634cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008e8469-5e59-4ca3-be74-1d6c47182112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Isolation Forest...\n",
      "computing metrics\n",
      "\n",
      "Running Local Outlier Factor...\n",
      "computing metrics\n",
      "\n",
      "Running kmeans...\n",
      "hmm\n",
      "computing metrics\n",
      "\n",
      "Isolation Forest Results:\n",
      "Mean Anomaly Score: 0.1074\n",
      "\n",
      "Local Outlier Factor Results:\n",
      "Mean Anomaly Score: 77692.2477\n",
      "\n",
      "kmeans Results:\n",
      "Mean Anomaly Score: -6.2427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Isolation Forest\": IsolationForest(random_state=42),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, novelty=True),\n",
    "    \"kmeans\": MiniBatchKMeans(n_clusters=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Fit models and collect results\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nRunning {name}...\")\n",
    "    \n",
    "    # Special handling\n",
    "    if name == \"kmeans\":\n",
    "        labels = model.fit_predict(X_scaled)\n",
    "        anomaly_scores = -labels  # Outliers are labeled as -1\n",
    "    elif name == \"Local Outlier Factor\":\n",
    "        model.fit(X_scaled)\n",
    "        anomaly_scores = -model.negative_outlier_factor_\n",
    "    else:\n",
    "        model.fit(X_scaled)\n",
    "        anomaly_scores = model.decision_function(X_scaled)\n",
    "    print('computing metrics')\n",
    "    # Compute metrics\n",
    "    mean_score = anomaly_scores.mean()\n",
    "\n",
    "    results[name] = {\n",
    "        \"Mean Anomaly Score\": mean_score\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a025eac-56f2-4ac1-994d-0372db4273be",
   "metadata": {},
   "source": [
    "# 7. Create a subsample of 250 datapoints, redo question 6, using Leave-one-out as the method of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3838c884-393c-42af-9505-941e452790f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Subsample the dataset to 250 points\n",
    "X_sampled = resample(X_scaled, n_samples=250, random_state=42, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea13c948-7209-493d-ad62-cef1e8f1de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Isolation Forest Results:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "Local Outlier Factor Results:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "kmeans Results:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "results = {name: {\"Precision\": [], \"Recall\": [], \"F1-Score\": []} for name in models}\n",
    "\n",
    "for train_index, test_index in loo.split(X_sampled):\n",
    "    X_train, X_test = X_sampled[train_index], X_sampled[test_index]\n",
    "    \n",
    "    true_label = [0]  # Assume the test point is an inlier\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if name == \"Local Outlier Factor\":\n",
    "            model.fit(X_train)\n",
    "            scores = -model.decision_function(X_test)  # LOF anomaly score\n",
    "        elif name == \"kmeans\":\n",
    "            model.fit(X_train)\n",
    "            test_distances = model.transform(X_test).min(axis=1)  # Min distance to a centroid\n",
    "            scores = -test_distances  # Higher distances are more anomalous (negative for consistency)\n",
    "            threshold = np.percentile(model.transform(X_train).min(axis=1), 95)\n",
    "            preds = (test_distances > threshold).astype(int)\n",
    "        else:\n",
    "            model.fit(X_train)\n",
    "            scores = model.decision_function(X_test)  # For models like IsolationForest, One-Class SVM\n",
    "        \n",
    "        # For other models (non-KMeans), apply the threshold\n",
    "        if name != \"kmeans\":\n",
    "            threshold = np.percentile(scores, 13)  # Threshold for other models\n",
    "            preds = (scores < threshold).astype(int)  # Lower scores = anomaly\n",
    "        \n",
    "        # DEBUG: Print scores and predictions\n",
    "        #rint(f\"\\nModel: {name}\")\n",
    "        #print(f\"Scores: {scores}\")\n",
    "        #print(f\"Predictions: {preds}\")\n",
    "        \n",
    "        # Compute metrics\n",
    "        precision = precision_score(true_label, preds, zero_division=0)\n",
    "        recall = recall_score(true_label, preds, zero_division=0)\n",
    "        f1 = f1_score(true_label, preds, zero_division=0)\n",
    "        \n",
    "        results[name][\"Precision\"].append(precision)\n",
    "        results[name][\"Recall\"].append(recall)\n",
    "        results[name][\"F1-Score\"].append(f1)\n",
    "\n",
    "# Aggregate results\n",
    "final_results = {model: {metric: np.mean(values) for metric, values in metrics.items()} for model, metrics in results.items()}\n",
    "\n",
    "# Display results\n",
    "for model, metrics in final_results.items():\n",
    "    print(f\"\\n{model} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf836b-b282-4376-bb53-e32c90567134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c85496f5-1b58-4de4-afea-541931f54b88",
   "metadata": {},
   "source": [
    "# 8. Use the feature selection algorithm to identify the 5 most important features for the task in question 6, for each algorithm. Does the anomaly detection improve using less features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2666adb-af2d-4d83-a046-55ea7f304a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Isolation Forest Results:\n",
      "Precision-Recall AUC Full: 1.0000\n",
      "Precision-Recall AUC Selected: 1.0000\n",
      "\n",
      "Local Outlier Factor Results:\n",
      "Precision-Recall AUC Full: 1.0000\n",
      "Precision-Recall AUC Selected: 1.0000\n",
      "\n",
      "kmeans Results:\n",
      "Precision-Recall AUC Full: 1.0000\n",
      "Precision-Recall AUC Selected: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "y_sampled = resample(y, n_samples=250, random_state=42, replace=False)\n",
    "# Assuming that `y_test` is binary (0 for inliers, 1 for anomalies)\n",
    "\n",
    "results = {name: {\"Precision-Recall AUC Full\": [], \"Precision-Recall AUC Selected\": []} for name in models}\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Ensuring y_sampled is binary (0 for normal, 1 for anomaly)\n",
    "y_sampled = np.array([0 if label == 'normal' else 1 for label in y_sampled])\n",
    "\n",
    "# Initialize the results dictionary\n",
    "results = {name: {\"Precision-Recall AUC Full\": [], \"Precision-Recall AUC Selected\": []} for name in models}\n",
    "\n",
    "# Using StratifiedKFold for better handling of the small dataset\n",
    "loo = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in loo.split(X_sampled, y_sampled):\n",
    "    X_train, X_test = X_sampled[train_index], X_sampled[test_index]\n",
    "    y_train, y_test = y_sampled[train_index], y_sampled[test_index]\n",
    "\n",
    "    # Feature Selection\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Full Feature Set\n",
    "        model.fit(X_train)\n",
    "        scores_full = model.decision_function(X_test) if hasattr(model, 'decision_function') else model.transform(X_test).min(axis=1)\n",
    "        \n",
    "        # Calculate Precision-Recall AUC for Full Feature Set\n",
    "        precision_full, recall_full, _ = precision_recall_curve(y_test, scores_full)\n",
    "        pr_auc_full = auc(recall_full, precision_full)\n",
    "\n",
    "        # Selected Feature Set\n",
    "        model.fit(X_train_selected)\n",
    "        scores_selected = model.decision_function(X_test_selected) if hasattr(model, 'decision_function') else model.transform(X_test_selected).min(axis=1)\n",
    "        \n",
    "        # Calculate Precision-Recall AUC for Selected Feature Set\n",
    "        precision_selected, recall_selected, _ = precision_recall_curve(y_test, scores_selected)\n",
    "        pr_auc_selected = auc(recall_selected, precision_selected)\n",
    "\n",
    "        # Store results\n",
    "        results[name][\"Precision-Recall AUC Full\"].append(pr_auc_full)\n",
    "        results[name][\"Precision-Recall AUC Selected\"].append(pr_auc_selected)\n",
    "\n",
    "# Step 3: Average Results\n",
    "final_results = {model: {metric: np.mean(values) for metric, values in metrics.items()} for model, metrics in results.items()}\n",
    "\n",
    "# Display Results\n",
    "for model, metrics in final_results.items():\n",
    "    print(f\"\\n{model} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff593b-b0ec-408d-8882-e107299ada3a",
   "metadata": {},
   "source": [
    "### Yes, detection improves with less features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8bafa-5623-4230-9761-86940a4f867a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
